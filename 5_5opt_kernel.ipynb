{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "source": [
    "This kernel is based on [my previous kernel](https://www.kaggle.com/kostyaatarik/not-a-3-and-3-halves-opt) and while it shares the same idea of permutating the chunks of the path it expands it to fives of points and handles permutations much faster by moving the code that finds the best permutation of chunks to numba which is a great tool to squeeze everything you can from python.\n",
    "\n",
    "As an initial path to start optimization from I'll use the output from [my another kernel](https://www.kaggle.com/kostyaatarik/shame-on-me)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "source": [
    "Import all that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_uuid": "4080f80d30b6e4702d2aac7c19e73d5e690574a3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numba\n",
    "from sympy import isprime, primerange\n",
    "from math import sqrt\n",
    "from sklearn.neighbors import KDTree\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from itertools import combinations, permutations\n",
    "from functools import lru_cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dc08acedd4b79e21759da2d92d01021659baa302"
   },
   "source": [
    "Read input data and define some arrays that we'll need later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "d5b03d9b02ebc2f734c1cbfa77bdcbbb7dda9730"
   },
   "outputs": [],
   "source": [
    "cities = pd.read_csv('cities.csv', index_col=['CityId'])\n",
    "XY = np.stack((cities.X.astype(np.float32), cities.Y.astype(np.float32)), axis=1)\n",
    "is_not_prime = np.array([0 if isprime(i) else 1 for i in cities.index], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6b64627e6cbaffffc873eb9302e0087136ec85a1"
   },
   "source": [
    "Define fast scoring functions using numba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "c678bfe47a584d041019dafd02bf48d44622cc09"
   },
   "outputs": [],
   "source": [
    "@numba.jit('f8(i8, i8, i8)', nopython=True, parallel=False)\n",
    "def cities_distance(offset, id_from, id_to):\n",
    "    xy_from, xy_to = XY[id_from], XY[id_to]\n",
    "    dx, dy = xy_from[0] - xy_to[0], xy_from[1] - xy_to[1]\n",
    "    distance = sqrt(dx * dx + dy * dy)\n",
    "    if offset % 10 == 9 and is_not_prime[id_from]:\n",
    "        return 1.1 * distance\n",
    "    return distance\n",
    "\n",
    "\n",
    "@numba.jit('f8(i4, i8[:])', nopython=True, parallel=False)\n",
    "def score_chunk(offset, chunk):\n",
    "    pure_distance, penalty = 0.0, 0.0\n",
    "    penalty_modulo = 9 - offset % 10\n",
    "    for path_index in numba.prange(chunk.shape[0] - 1):\n",
    "        id_from, id_to = chunk[path_index], chunk[path_index+1]\n",
    "        xy_from, xy_to = XY[id_from], XY[id_to]\n",
    "        dx, dy = xy_from[0] - xy_to[0], xy_from[1] - xy_to[1]\n",
    "        distance = sqrt(dx * dx + dy * dy)\n",
    "        pure_distance += distance\n",
    "        if path_index % 10 == penalty_modulo and is_not_prime[id_from]:\n",
    "            penalty += distance\n",
    "    return pure_distance + 0.1 * penalty\n",
    "\n",
    "\n",
    "@numba.jit('f8(i8[:])', nopython=True, parallel=False)\n",
    "def score_path(path):\n",
    "    return score_chunk(0, path)\n",
    "\n",
    "\n",
    "@numba.jit\n",
    "def chunk_scores(chunk):\n",
    "    scores = np.zeros(10)\n",
    "    pure_distance = 0\n",
    "    for i in numba.prange(chunk.shape[0] - 1):\n",
    "        id_from, id_to = chunk[i], chunk[i+1]\n",
    "        xy_from, xy_to = XY[id_from], XY[id_to]\n",
    "        dx, dy = xy_from[0] - xy_to[0], xy_from[1] - xy_to[1]\n",
    "        distance = sqrt(dx * dx + dy * dy)\n",
    "        pure_distance += distance\n",
    "        if is_not_prime[id_from]:\n",
    "            scores[9-i%10] += distance\n",
    "    scores *= 0.1\n",
    "    scores += pure_distance\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3b2622874752149ec22bd669219b0540c2a86d56"
   },
   "source": [
    "The part below is different from my previous kernel. This is how we'll handle permutations in numba.\n",
    "\n",
    "Instead of passing list of chunks of different sizes to the function 'score_compound_chunk' we'll pass just the lists of their first and last elements and their lenghts. By calling this function from the function 'best_score_permutation_index' the index of the best permutation will be found in numba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "ae83ba78b4209885a6b8425e40bccb555fe9fa6f"
   },
   "outputs": [],
   "source": [
    "@numba.jit('f8(i8, i8, i8[:], i8[:], i8[:], i8, f8[:,:], i8[:])', nopython=True, parallel=False)\n",
    "def score_compound_chunk(offset, head, firsts, lasts, lens, tail, scores, indexes):\n",
    "    score = 0.0\n",
    "    last_city_id = head\n",
    "    for i in numba.prange(len(indexes)):\n",
    "        index = indexes[i]\n",
    "        first, last, chunk_len = firsts[index], lasts[index], lens[index]\n",
    "        score += cities_distance(offset, last_city_id, first)\n",
    "        score += scores[index, (offset + 1) % 10]\n",
    "        last_city_id = last\n",
    "        offset += chunk_len\n",
    "    return score + cities_distance(offset, last_city_id, tail)\n",
    "\n",
    "\n",
    "@numba.jit('i8(i8, i8, i8[:], i8[:], i8[:], i8, f8[:,:], i8[:,:], f8)', nopython=True, parallel=False)\n",
    "def best_score_permutation_index(offset, head, firsts, lasts, lens, tail, scores, indexes, best_score):\n",
    "    best_index = -1\n",
    "    for i in numba.prange(len(indexes)):\n",
    "        score = score_compound_chunk(offset, head, firsts, lasts, lens, tail, scores, indexes[i])\n",
    "        if score < best_score:\n",
    "            best_index, best_score = i, score\n",
    "    return best_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "190b0273a4291ad1985bee71aa5a41611adfbe16"
   },
   "source": [
    "Precompute close cities fives using KDTree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "96b82655133cda1be8b882ea0ab64ec96939e33e"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31e265ecd73d430ea5f1099751b3437f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=197769), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-753b5b549a86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfives\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mdists\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneibs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mXY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcomb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneibs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/neighbors/binary_tree.pxi\u001b[0m in \u001b[0;36msklearn.neighbors.kd_tree.BinaryTree.query\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32msklearn/neighbors/binary_tree.pxi\u001b[0m in \u001b[0;36msklearn.neighbors.kd_tree.NeighborsHeap.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mfull\u001b[0;34m(shape, fill_value, dtype, order)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m     \"\"\"\n\u001b[1;32m    270\u001b[0m     \u001b[0mReturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnew\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilled\u001b[0m \u001b[0;32mwith\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kdt = KDTree(XY)\n",
    "\n",
    "fives = set()\n",
    "for i in tqdm(cities.index):\n",
    "    dists, neibs = kdt.query([XY[i]], 9)\n",
    "    for comb in combinations(neibs[0], 5):\n",
    "        if all(comb):\n",
    "            fives.add(tuple(sorted(comb)))\n",
    "    neibs = kdt.query_radius([XY[i]], 10, count_only=False, return_distance=False)\n",
    "    for comb in combinations(neibs[0], 5):\n",
    "        if all(comb):\n",
    "            fives.add(tuple(sorted(comb)))\n",
    "            \n",
    "print(f'{len(fives)} cities fives are selected.')\n",
    "\n",
    "# sort fives by distance\n",
    "@numba.jit('f8(i8[:])', nopython=True, parallel=False)\n",
    "def sum_distance(ids):\n",
    "    res = 0\n",
    "    for i in numba.prange(len(ids)):\n",
    "        for j in numba.prange(i + 1, len(ids)):\n",
    "            res += cities_distance(0, ids[i], ids[j])\n",
    "    return res\n",
    "\n",
    "fives = np.array(list(fives))\n",
    "distances = np.array(list(map(sum_distance, tqdm(fives))))\n",
    "order = distances.argsort()\n",
    "fives = fives[order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b6d155718a87c60380400af6a7516af256ad62ce"
   },
   "source": [
    "Load the initial path to start optimization from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b7260b66eeec537d44d341888224ad3fd8823407"
   },
   "outputs": [],
   "source": [
    "path = np.array(pd.read_csv('submissions/3.5_after_LKH_1_5.csv').Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_submission(name, path):\n",
    "    pd.DataFrame({'Path': path}).to_csv(f'{name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "50e3d803ef50707fa8b522044cad69ddc22f1b09"
   },
   "source": [
    "Use the optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1734f1368fb55ad8efb4380f6c7265d481947897"
   },
   "outputs": [],
   "source": [
    "@lru_cache(maxsize=None)\n",
    "def indexes_permutations(n):\n",
    "    return np.array(list(map(list, permutations(range(n)))))\n",
    "\n",
    "\n",
    "path_index = np.argsort(path[:-1])\n",
    "print(f'Total score is {score_path(path):.2f}.')\n",
    "for _ in range(2):\n",
    "    for ids in tqdm(fives[:2 * 10**6]):\n",
    "        i1, i2, i3, i4, i5 = np.sort(path_index[ids])\n",
    "        head, tail = path[i1-1], path[i5+1]\n",
    "        chunks = [path[i1:i1+1], path[i1+1:i2], path[i2:i2+1], path[i2+1:i3],\n",
    "                  path[i3:i3+1], path[i3+1:i4], path[i4:i4+1], path[i4+1:i5], path[i5:i5+1]]\n",
    "        chunks = [chunk for chunk in chunks if len(chunk)]\n",
    "        scores = np.array([chunk_scores(chunk) for chunk in chunks])\n",
    "        lens = np.array([len(chunk) for chunk in chunks])\n",
    "        firsts = np.array([chunk[0] for chunk in chunks])\n",
    "        lasts = np.array([chunk[-1] for chunk in chunks])\n",
    "        best_score = score_compound_chunk(i1-1, head, firsts, lasts, lens, tail, scores, indexes_permutations(len(chunks))[0])\n",
    "        index = best_score_permutation_index(i1-1, head, firsts, lasts, lens, tail, scores, indexes_permutations(len(chunks)), best_score)\n",
    "        if index > 0:\n",
    "            perm = [chunks[i] for i in indexes_permutations(len(chunks))[index]]\n",
    "            path[i1-1:i5+2] = np.concatenate([[head], np.concatenate(perm), [tail]])\n",
    "            path_index = np.argsort(path[:-1])\n",
    "            print(f'New total score is {score_path(path):.3f}. Permutating path at indexes {i1}, {i2}, {i3}, {i4}, {i5}.')\n",
    "            make_submission('5.5_after_LKH_1_5', path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b66ddc715194f2e335eeb7f71d2d758b37b277e9"
   },
   "source": [
    "Save the result path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c840af354f2152858c81a62f16219d679f714ca1"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
